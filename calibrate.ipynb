{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from policyengine_us import Microsimulation\n",
    "import plotly.express as px\n",
    "\n",
    "simulation = Microsimulation()\n",
    "parameters = simulation.tax_benefit_system.parameters.calibration(\"2023-01-01\")\n",
    "\n",
    "household_weights = torch.tensor(simulation.calculate(\"household_weight\", 2023).values, dtype=torch.float32)\n",
    "weight_adjustment = torch.tensor(np.random.random(household_weights.shape) * 0, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "values_df = pd.DataFrame()\n",
    "targets = {}\n",
    "equivalisation = {}\n",
    "\n",
    "# We need to normalise the targets. Common regression targets are often 1e1 to 1e3 (this informs the scale of the learning rate).\n",
    "COUNT_HOUSEHOLDS = household_weights.sum().item()\n",
    "FINANCIAL_EQUIVALISATION = COUNT_HOUSEHOLDS\n",
    "POPULATION_EQUIVALISATION = COUNT_HOUSEHOLDS / 1e5\n",
    "\n",
    "# Financial totals\n",
    "values_df[\"adjusted_gross_income\"] = simulation.calculate(\"adjusted_gross_income\", 2023, map_to=\"household\").values\n",
    "targets[\"adjusted_gross_income\"] = parameters.agi_by_source.projections.adjusted_gross_income\n",
    "equivalisation[\"adjusted_gross_income\"] = FINANCIAL_EQUIVALISATION\n",
    "\n",
    "values_df[\"employment_income\"] = simulation.calculate(\"employment_income\", 2023, map_to=\"household\").values\n",
    "targets[\"employment_income\"] = parameters.agi_by_source.projections.employment_income\n",
    "equivalisation[\"employment_income\"] = FINANCIAL_EQUIVALISATION\n",
    "\n",
    "values_df[\"taxable_interest_and_ordinary_dividends\"] = simulation.calculate(\"taxable_interest_and_ordinary_dividends\", 2023, map_to=\"household\").values\n",
    "targets[\"taxable_interest_and_ordinary_dividends\"] = parameters.agi_by_source.projections.taxable_interest_and_ordinary_dividends\n",
    "equivalisation[\"taxable_interest_and_ordinary_dividends\"] = FINANCIAL_EQUIVALISATION\n",
    "\n",
    "values_df[\"qualified_dividend_income\"] = simulation.calculate(\"qualified_dividend_income\", 2023, map_to=\"household\").values\n",
    "targets[\"qualified_dividend_income\"] = parameters.agi_by_source.projections.qualified_dividend_income\n",
    "equivalisation[\"qualified_dividend_income\"] = FINANCIAL_EQUIVALISATION\n",
    "\n",
    "# adjusted_gross_income, employment_income, taxable_interest_and_ordinary_dividends, qualified_dividend_income, net_capital_gain, self_employment_income, taxable_pension_income, taxable_social_security, irs_other_income, above_the_line_deductions\n",
    "\n",
    "values\n",
    "\n",
    "# Total population\n",
    "values_df[\"population\"] = simulation.calculate(\"people\", 2023, map_to=\"household\").values\n",
    "targets[\"population\"] = parameters.populations.total\n",
    "equivalisation[\"population\"] = POPULATION_EQUIVALISATION\n",
    "\n",
    "# Population by 5-year age group\n",
    "age = simulation.calculate(\"age\").values\n",
    "for lower_age_group in range(0, 90, 5):\n",
    "    in_age_range = (age >= lower_age_group) & (age < lower_age_group + 5)\n",
    "    count_people_in_range = simulation.map_result(in_age_range, \"person\", \"household\")\n",
    "    values_df[f\"population_{lower_age_group}_to_{lower_age_group + 5}\"] = count_people_in_range\n",
    "    targets[f\"population_{lower_age_group}_to_{lower_age_group + 5}\"] = (household_weights.numpy() * count_people_in_range).sum()\n",
    "    equivalisation[f\"population_{lower_age_group}_to_{lower_age_group + 5}\"] = POPULATION_EQUIVALISATION\n",
    "\n",
    "targets_array = torch.tensor(list(targets.values()), dtype=torch.float32)\n",
    "equivalisation_factors_array = torch.tensor(list(equivalisation.values()), dtype=torch.float32)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "def aggregate(adjusted_weights: torch.Tensor, values: pd.DataFrame) -> torch.Tensor:\n",
    "    broadcasted_weights = adjusted_weights.reshape(-1, 1)\n",
    "    weighted_values = torch.matmul(\n",
    "        broadcasted_weights.T, \n",
    "        torch.tensor(values.values, dtype=torch.float32)\n",
    "    )\n",
    "    return weighted_values\n",
    "\n",
    "training_log_df = pd.DataFrame()\n",
    "\n",
    "for i in range(10_000):\n",
    "    adjusted_weights = torch.relu(household_weights + weight_adjustment)\n",
    "    result = aggregate(adjusted_weights, values_df) / equivalisation_factors_array\n",
    "    loss = torch.sum((result - targets_array / equivalisation_factors_array) ** 2)\n",
    "    loss.backward()\n",
    "    if i % 50 == 0:\n",
    "        current_loss = loss.item()\n",
    "        current_aggregates = (result * equivalisation_factors_array).detach().numpy()[0]\n",
    "        training_log_df = training_log_df.append(\n",
    "            pd.DataFrame({\n",
    "                \"name\": list(targets.keys()),\n",
    "                \"epoch\": [i] * len(targets),\n",
    "                \"value\": list(current_aggregates),\n",
    "                \"target\": list(targets.values()),\n",
    "            })\n",
    "        )\n",
    "    weight_adjustment.data -= 1e-1 * weight_adjustment.grad\n",
    "    weight_adjustment.grad.zero_()\n",
    "\n",
    "training_log_df.to_csv(\"training_log.csv.gz\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
